import streamlit as st
import json
import os
from main import analyze_urls, GEOAnalyzer
from report import generate_html_report, generate_csv_export
import time

st.set_page_config(
    page_title="GEO Analyzer",
    page_icon="üöÄ",
    layout="wide"
)

st.title("üöÄ GEO AI Readiness Analyzer")
st.markdown("**Generative Engine Optimization** elemz√©s eszk√∂z")

# Sidebar be√°ll√≠t√°sok
st.sidebar.header("‚öôÔ∏è Be√°ll√≠t√°sok")

# API kulcs be√°ll√≠t√°s
api_key = st.sidebar.text_input(
    "Google PageSpeed API kulcs:",
    type="password",
    help="Opcion√°lis - PageSpeed Insights-hoz sz√ºks√©ges"
)

# Elemz√©si opci√≥k
skip_pagespeed = st.sidebar.checkbox(
    "PageSpeed √°tugr√°sa", 
    value=not bool(api_key),
    help="Gyorsabb elemz√©s PageSpeed n√©lk√ºl"
)

parallel_processing = st.sidebar.checkbox(
    "P√°rhuzamos feldolgoz√°s", 
    value=True,
    help="T√∂bb URL egyidej≈± elemz√©se (gyorsabb)"
)

max_workers = st.sidebar.slider(
    "P√°rhuzamos sz√°lak sz√°ma",
    min_value=1,
    max_value=5,
    value=2,
    help="T√∂bb sz√°l = gyorsabb, de t√∂bb terhel√©s"
)

st.sidebar.subheader("üöÄ Fejlett funkci√≥k")

generate_advanced_reports = st.sidebar.checkbox(
    "Fejlett jelent√©sek gener√°l√°sa",
    value=True,
    help="Executive, technikai √©s action plan jelent√©sek"
)

report_type = st.sidebar.selectbox(
    "Jelent√©s t√≠pusa:",
    ["executive", "technical", "action_plan", "competitor"],
    help="Milyen t√≠pus√∫ r√©szletes jelent√©st szeretn√©l?"
)

enable_ai_fixes = st.sidebar.checkbox(
    "Automatikus jav√≠t√°si javaslatok",
    value=True,
    help="AI-alap√∫ optimaliz√°l√°si javaslatok gener√°l√°sa"
)

platform_focus = st.sidebar.multiselect(
    "AI platform f√≥kusz:",
    ["ChatGPT", "Claude", "Gemini", "Bing Chat"],
    default=["ChatGPT", "Claude"],
    help="Melyik AI platformokra optimaliz√°lj?"
)

# F≈ëoldal
col1, col2 = st.columns([2, 1])

with col1:
    st.header("üìù URL-ek megad√°sa")
    
    # URL input m√≥dok
    input_method = st.radio(
        "URL megad√°s m√≥dja:",
        ["Sz√∂veges lista", "F√°jl felt√∂lt√©s"]
    )
    
    if input_method == "Sz√∂veges lista":
        urls_text = st.text_area(
            "URL-ek (soronk√©nt egy URL):",
            height=200,
            placeholder="https://example.com\nhttps://another-site.com\nhttps://third-site.com"
        )
        url_list = [url.strip() for url in urls_text.split('\n') if url.strip()]
    
    else:
        uploaded_file = st.file_uploader(
            "URL lista felt√∂lt√©se",
            type=['txt', 'csv'],
            help="Soronk√©nt egy URL a f√°jlban"
        )
        
        url_list = []
        if uploaded_file:
            content = str(uploaded_file.read(), "utf-8")
            url_list = [url.strip() for url in content.split('\n') if url.strip()]
    
    # URL el≈ën√©zet
    if url_list:
        st.success(f"‚úÖ {len(url_list)} URL bet√∂ltve")
        with st.expander("URL lista el≈ën√©zete"):
            for i, url in enumerate(url_list[:10], 1):
                st.text(f"{i}. {url}")
            if len(url_list) > 10:
                st.text(f"... √©s m√©g {len(url_list) - 10} URL")

with col2:
    st.header("üìä El≈ëz≈ë elemz√©sek")
    
    # Kor√°bbi jelent√©sek list√°z√°sa
    json_files = [f for f in os.listdir('.') if f.endswith('_report.json')]
    html_files = [f for f in os.listdir('.') if f.endswith('.html') and 'report' in f]
    
    if json_files:
        st.subheader("JSON jelent√©sek:")
        for file in json_files[:5]:
            if st.button(f"üìÅ {file}", key=f"json_{file}"):
                with open(file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                st.json(data)
    
    if html_files:
        st.subheader("HTML jelent√©sek:")
        for file in html_files[:5]:
            st.markdown(f"üìÑ [{file}](./{file})")

# Elemz√©s ind√≠t√°sa
st.header("üöÄ Elemz√©s ind√≠t√°sa")

if st.button("‚ñ∂Ô∏è Elemz√©s kezd√©se", type="primary", disabled=not bool(url_list)):
    if not url_list:
        st.error("‚ùå Nem adt√°l meg URL-eket!")
    else:
        # Progress bar √©s status
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            # Id≈ëm√©r√©s kezd√©se
            start_time = time.time()
            
            status_text.text("üîç Elemz√©s inicializ√°l√°sa...")
            progress_bar.progress(10)
            
            # F√°jln√©v gener√°l√°s timestamp-pel
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            json_filename = f"geo_analysis_{timestamp}.json"
            html_filename = f"geo_report_{timestamp}.html"
            
            status_text.text("üìä URL-ek elemz√©se folyamatban...")
            progress_bar.progress(20)
            
            # Elemz√©s futtat√°sa
            analyze_urls(
                url_list=url_list,
                api_key=api_key if not skip_pagespeed else None,
                output_file=json_filename,
                parallel=parallel_processing
            )
            
            progress_bar.progress(70)
            status_text.text("üìã HTML jelent√©s gener√°l√°sa...")
            
            # HTML jelent√©s
            generate_html_report(json_filename, html_filename)
            
            progress_bar.progress(90)
            status_text.text("üìä CSV export...")
            
            # CSV export
            csv_filename = f"geo_export_{timestamp}.csv"
            generate_csv_export(json_filename, csv_filename)
            
            progress_bar.progress(100)
            
            # Sikeres befejez√©s
            elapsed_time = time.time() - start_time
            status_text.text(f"‚úÖ Elemz√©s befejezve! ({elapsed_time:.1f} m√°sodperc)")
            
            # Eredm√©nyek megjelen√≠t√©se
            st.success("üéâ Elemz√©s sikeres!")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                with open(json_filename, 'rb') as f:
                    st.download_button(
                        "üìä JSON let√∂lt√©s",
                        f,
                        file_name=json_filename,
                        mime="application/json"
                    )
            
            with col2:
                with open(html_filename, 'rb') as f:
                    st.download_button(
                        "üìÑ HTML jelent√©s",
                        f,
                        file_name=html_filename,
                        mime="text/html"
                    )
            
            with col3:
                with open(csv_filename, 'rb') as f:
                    st.download_button(
                        "üìà CSV export",
                        f,
                        file_name=csv_filename,
                        mime="text/csv"
                    )
            
            # √ñsszefoglal√≥ megjelen√≠t√©se
            with open(json_filename, 'r', encoding='utf-8') as f:
                results = json.load(f)
            
            st.header("üìà √ñsszefoglal√≥")
            
            col1, col2, col3, col4 = st.columns(4)
            
            valid_results = [r for r in results if 'ai_readiness_score' in r]
            
            with col1:
                st.metric("Elemzett oldalak", len(results))
            
            with col2:
                if valid_results:
                    avg_score = sum(r['ai_readiness_score'] for r in valid_results) / len(valid_results)
                    st.metric("√Åtlagos AI Score", f"{avg_score:.1f}/100")
            
            with col3:
                excellent_count = sum(1 for r in valid_results if r['ai_readiness_score'] >= 70)
                st.metric("Kiv√°l√≥ oldalak", excellent_count)
            
            with col4:
                poor_count = sum(1 for r in valid_results if r['ai_readiness_score'] < 50)
                st.metric("Fejlesztend≈ë", poor_count)
            
            # R√©szletes eredm√©nyek
            if valid_results:
                st.subheader("üèÜ Legjobb eredm√©nyek")
                sorted_results = sorted(valid_results, key=lambda x: x['ai_readiness_score'], reverse=True)
                
                for i, result in enumerate(sorted_results[:5], 1):
                    score = result['ai_readiness_score']
                    url = result['url']
                    
                    # Sz√≠n a score alapj√°n
                    if score >= 70:
                        color = "üü¢"
                    elif score >= 50:
                        color = "üü°"
                    else:
                        color = "üî¥"
                    
                    st.write(f"{color} **{i}.** {url} - **{score}/100**")
            
        except Exception as e:
            st.error(f"‚ùå Hiba t√∂rt√©nt az elemz√©s sor√°n: {str(e)}")
            status_text.text("‚ùå Elemz√©s megszak√≠tva")

# Inform√°ci√≥s szekci√≥
with st.expander("‚ÑπÔ∏è Inform√°ci√≥ a GEO Analyzer-r√≥l"):
    st.markdown("""
    ### Mi az a GEO (Generative Engine Optimization)?
    
    A **Generative Engine Optimization** az AI-alap√∫ keres≈ëmotorok (mint ChatGPT, Bard, Claude) sz√°m√°ra val√≥ optimaliz√°l√°s.
    
    ### Mit ellen≈ëriz az alkalmaz√°s?
    
    ‚úÖ **Technikai SEO**
    - Robots.txt √©s Sitemap
    - Meta title √©s description optimaliz√°l√°sa
    - Heading strukt√∫ra (H1-H6)
    - Mobile-friendly design
    
    ‚úÖ **Struktur√°lt adatok**
    - Schema.org markup
    - Open Graph meta tagek
    - Twitter Card t√°mogat√°s
    
    ‚úÖ **AI-readiness**
    - Tartalom struktur√°lts√°ga
    - G√©pi olvashat√≥s√°g
    - AI-bar√°t form√°z√°s
    
    ‚úÖ **Teljes√≠tm√©ny**
    - PageSpeed Insights pontsz√°mok
    - Core Web Vitals metrik√°k
    
    ### Hogyan haszn√°ld?
    
    1. Add meg az elemezni k√≠v√°nt URL-eket
    2. Opcion√°lisan √°ll√≠tsd be a Google PageSpeed API kulcsot
    3. Ind√≠tsd el az elemz√©st
    4. T√∂ltsd le a jelent√©seket (JSON/HTML/CSV)
    
    ### API kulcs beszerz√©se
    
    A PageSpeed Insights API kulcshoz menj a [Google Cloud Console](https://console.cloud.google.com/)-ra √©s enged√©lyezd a PageSpeed Insights API-t.
    """)

# Footer
st.markdown("---")
st.markdown("üöÄ **GEO Analyzer** | K√©sz√≠tette: Ecsedi Tam√°s | 2025")