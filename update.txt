def generate_html_report(json_file: str = "ai_readiness_full_report.json", 
                        output_file: str = "report.html") -> None:
    """
    Enhanced HTML jelent√©s gener√°l√°sa a GEO elemz√©s eredm√©nyeib≈ël
    """
    try:
        with open(json_file, "r", encoding="utf-8") as f:
            data = json.load(f)
    except FileNotFoundError:
        print(f"‚ùå Hiba: {json_file} nem tal√°lhat√≥!")
        return
    except json.JSONDecodeError:
        print(f"‚ùå Hiba: {json_file} nem √©rv√©nyes JSON!")
        return

    # T√≠pus felismer√©s: enhanced vs standard
    is_enhanced = any(
        result.get('ai_content_evaluation') or 
        result.get('schema', {}).get('validation_status') == 'enhanced'
        for result in data if isinstance(result, dict)
    )
    
    # √Åtlagos score sz√°m√≠t√°sa
    valid_results = [r for r in data if isinstance(r, dict) and 'ai_readiness_score' in r and 'error' not in r]
    avg_score = sum(r['ai_readiness_score'] for r in valid_results) / len(valid_results) if valid_results else 0
    
    # Enhanced statisztik√°k
    ai_enhanced_count = len([r for r in valid_results if r.get('ai_content_evaluation')])
    schema_enhanced_count = len([r for r in valid_results if r.get('schema', {}).get('validation_status') == 'enhanced'])
    
    # HTML template
    report_title = "Enhanced GEO AI Readiness Report" if is_enhanced else "GEO AI Readiness Report"
    html_content = f"""
<!DOCTYPE html>
<html lang="hu">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{report_title} - {datetime.now().strftime('%Y-%m-%d')}</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap" rel="stylesheet">
    <style>
        * {{
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }}
        
        body {{
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, {'#667eea 0%, #764ba2 100%' if is_enhanced else '#4facfe 0%, #00f2fe 100%'});
            min-height: 100vh;
            padding: 20px;
        }}
        
        .container {{
            max-width: 1400px;
            margin: 0 auto;
        }}
        
        header {{
            background: white;
            border-radius: 20px;
            padding: 30px;
            margin-bottom: 30px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
            {'border-left: 5px solid #667eea;' if is_enhanced else ''}
        }}
        
        h1 {{
            color: #333;
            font-size: 2.5rem;
            margin-bottom: 10px;
        }}
        
        .enhanced-badge {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 5px 15px;
            border-radius: 20px;
            font-size: 0.8rem;
            font-weight: 600;
            display: inline-block;
            margin-left: 10px;
        }}
        
        .summary {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin-top: 20px;
        }}
        
        .summary-card {{
            background: #f8f9fa;
            padding: 20px;
            border-radius: 10px;
            text-align: center;
        }}
        
        .summary-card.enhanced {{
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            color: white;
        }}
        
        .summary-card .value {{
            font-size: 2rem;
            font-weight: 700;
            color: #667eea;
        }}
        
        .summary-card.enhanced .value {{
            color: white;
        }}
        
        .summary-card .label {{
            font-size: 0.9rem;
            color: #666;
            margin-top: 5px;
        }}
        
        .summary-card.enhanced .label {{
            color: rgba(255,255,255,0.9);
        }}
        
        .site-card {{
            background: white;
            border-radius: 20px;
            padding: 30px;
            margin-bottom: 30px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
            {'border-left: 5px solid #667eea;' if is_enhanced else ''}
        }}
        
        .site-header {{
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 30px;
            padding-bottom: 20px;
            border-bottom: 2px solid #f0f0f0;
        }}
        
        .site-url {{
            font-size: 1.5rem;
            font-weight: 600;
            color: #333;
        }}
        
        .enhancement-badges {{
            display: flex;
            gap: 10px;
            margin: 10px 0;
        }}
        
        .enhancement-badge {{
            padding: 4px 8px;
            border-radius: 12px;
            font-size: 0.7rem;
            font-weight: 600;
        }}
        
        .badge-ai {{
            background: #e3f2fd;
            color: #1976d2;
        }}
        
        .badge-schema {{
            background: #f3e5f5;
            color: #7b1fa2;
        }}
        
        .badge-cache {{
            background: #e8f5e8;
            color: #2e7d32;
        }}
        
        .score-badge {{
            display: inline-flex;
            align-items: center;
            justify-content: center;
            width: 80px;
            height: 80px;
            border-radius: 50%;
            font-size: 1.5rem;
            font-weight: 700;
            color: white;
        }}
        
        .score-excellent {{ background: linear-gradient(135deg, #00c851 0%, #00a846 100%); }}
        .score-good {{ background: linear-gradient(135deg, #4caf50 0%, #45a049 100%); }}
        .score-average {{ background: linear-gradient(135deg, #ffc107 0%, #e0a800 100%); }}
        .score-poor {{ background: linear-gradient(135deg, #ff4444 0%, #cc0000 100%); }}
        
        .metrics-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }}
        
        .metric-item {{
            background: #f8f9fa;
            padding: 20px;
            border-radius: 10px;
            border-left: 4px solid #667eea;
        }}
        
        .metric-item.ai-enhanced {{
            background: linear-gradient(135deg, #ffecd2 0%, #fcb69f 100%);
            border-left-color: #ff6b6b;
        }}
        
        .metric-title {{
            font-weight: 600;
            color: #333;
            margin-bottom: 10px;
        }}
        
        .metric-value {{
            color: #666;
            font-size: 0.9rem;
        }}
        
        .platform-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin: 20px 0;
        }}
        
        .platform-card {{
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            padding: 15px;
            border-radius: 10px;
            text-align: center;
        }}
        
        .platform-card.ai-enhanced {{
            background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%);
        }}
        
        .platform-name {{
            font-weight: 600;
            color: #333;
            margin-bottom: 10px;
        }}
        
        .platform-score {{
            font-size: 2rem;
            font-weight: 700;
            color: #667eea;
        }}
        
        .platform-level {{
            font-size: 0.8rem;
            color: #666;
            margin-top: 5px;
        }}
        
        .ai-scores {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            border-radius: 15px;
            margin: 20px 0;
        }}
        
        .ai-score-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 15px;
            margin-top: 15px;
        }}
        
        .ai-score-item {{
            text-align: center;
            background: rgba(255,255,255,0.1);
            padding: 10px;
            border-radius: 10px;
        }}
        
        .ai-score-value {{
            font-size: 1.5rem;
            font-weight: 700;
        }}
        
        .ai-score-label {{
            font-size: 0.8rem;
            opacity: 0.9;
            margin-top: 5px;
        }}
        
        .chart-container {{
            width: 100%;
            max-width: 500px;
            margin: 20px auto;
        }}
        
        .charts-row {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
            gap: 30px;
            margin: 30px 0;
        }}
        
        .tabs {{
            display: flex;
            gap: 10px;
            margin: 20px 0;
            border-bottom: 2px solid #e0e0e0;
        }}
        
        .tab {{
            padding: 10px 20px;
            background: none;
            border: none;
            cursor: pointer;
            font-weight: 600;
            color: #666;
            transition: all 0.3s;
        }}
        
        .tab.active {{
            color: #667eea;
            border-bottom: 3px solid #667eea;
        }}
        
        .tab-content {{
            display: none;
            padding: 20px 0;
        }}
        
        .tab-content.active {{
            display: block;
        }}
        
        table {{
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }}
        
        th, td {{
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid #e0e0e0;
        }}
        
        th {{
            background: #f8f9fa;
            font-weight: 600;
            color: #333;
        }}
        
        .check-icon {{ color: #00c851; }}
        .cross-icon {{ color: #ff4444; }}
        
        .footer {{
            text-align: center;
            color: white;
            margin-top: 50px;
            padding: 20px;
        }}
        
        .alert-box {{
            margin-top: 20px;
            padding: 15px;
            border-radius: 8px;
            border-left: 4px solid;
        }}
        
        .alert-critical {{
            background: #f8d7da;
            border-color: #dc3545;
            color: #721c24;
        }}
        
        .alert-info {{
            background: #d1ecf1;
            border-color: #17a2b8;
            color: #0c5460;
        }}
        
        .alert-warning {{
            background: #fff3cd;
            border-color: #ffc107;
            color: #856404;
        }}
        
        .alert-success {{
            background: #d4edda;
            border-color: #28a745;
            color: #155724;
        }}
        
        .progress-bar {{
            width: 100%;
            height: 20px;
            background: #e0e0e0;
            border-radius: 10px;
            overflow: hidden;
            margin: 10px 0;
        }}
        
        .progress-fill {{
            height: 100%;
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
            transition: width 0.3s;
        }}
        
        .ai-metrics-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 10px;
            margin: 15px 0;
        }}
        
        .ai-metric {{
            background: #fff;
            padding: 10px;
            border-radius: 8px;
            text-align: center;
            border: 1px solid #e0e0e0;
        }}
        
        .ai-metric-label {{
            font-size: 0.8rem;
            color: #666;
            margin-bottom: 5px;
        }}
        
        .ai-metric-value {{
            font-size: 1.2rem;
            font-weight: 600;
            color: #333;
        }}
        
        @media (max-width: 768px) {{
            h1 {{ font-size: 1.8rem; }}
            .site-url {{ font-size: 1.2rem; }}
            .charts-row {{ grid-template-columns: 1fr; }}
            .metrics-grid {{ grid-template-columns: 1fr; }}
            .platform-grid {{ grid-template-columns: repeat(2, 1fr); }}
        }}
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>üöÄ {report_title}{'<span class="enhanced-badge">AI ENHANCED</span>' if is_enhanced else ''}</h1>
            <p style="color: #666;">Generative Engine Optimization elemz√©s - {datetime.now().strftime('%Y. %m. %d. %H:%M')}</p>
            
            <div class="summary">
                <div class="summary-card">
                    <div class="value">{len(data)}</div>
                    <div class="label">Elemzett oldalak</div>
                </div>
                <div class="summary-card">
                    <div class="value">{fmt(avg_score, 1)}</div>
                    <div class="label">√Åtlagos AI Readiness</div>
                </div>
                <div class="summary-card">
                    <div class="value">{sum(1 for s in valid_results if s.get('ai_readiness_score', 0) >= 70)}</div>
                    <div class="label">Kiv√°l√≥ oldalak</div>
                </div>
                <div class="summary-card">
                    <div class="value">{sum(1 for s in valid_results if s.get('ai_readiness_score', 0) < 50)}</div>
                    <div class="label">Fejlesztend≈ë</div>
                </div>"""
    
    # Enhanced statisztik√°k hozz√°ad√°sa
    if is_enhanced:
        html_content += f"""
                <div class="summary-card enhanced">
                    <div class="value">{ai_enhanced_count}</div>
                    <div class="label">AI Enhanced</div>
                </div>
                <div class="summary-card enhanced">
                    <div class="value">{schema_enhanced_count}</div>
                    <div class="label">Schema Enhanced</div>
                </div>"""
    
    html_content += """
            </div>
        </header>
"""

    # Minden oldal feldolgoz√°sa (enhanced v√°ltozat)
    for idx, site in enumerate(data):
        if not isinstance(site, dict):
            continue
            
        url = site.get("url", "N/A")
        score = site.get("ai_readiness_score", 0)
        uid = f"site_{idx}_{re.sub(r'[^a-zA-Z0-9]', '_', url)}"
        
        # Enhanced jelz≈ëk
        has_ai_eval = bool(site.get('ai_content_evaluation'))
        has_schema_enhanced = site.get('schema', {}).get('validation_status') == 'enhanced'
        was_cached = site.get('cached', False)
        
        # Score sz√≠n meghat√°roz√°sa
        score_class = badge_class(score)
        
        # Adatok kinyer√©se
        meta_data = site.get("meta_and_headings", {})
        schema_data = site.get("schema", {})
        mobile = site.get("mobile_friendly", {})
        psi = site.get("pagespeed_insights", {})
        ai_metrics = site.get("ai_metrics", {})
        ai_summary = site.get("ai_metrics_summary", {})
        content_quality = site.get("content_quality", {})
        platform_analysis = site.get("platform_analysis", {})
        platform_suggestions = site.get("platform_suggestions", {})
        auto_fixes = site.get("auto_fixes", {})
        
        # Enhanced adatok
        ai_content_eval = site.get("ai_content_evaluation", {})
        ai_readability = site.get("ai_readability", {})
        ai_factual = site.get("ai_factual_check", {})
        
        html_content += f"""
        <div class="site-card">
            <div class="site-header">
                <div>
                    <div class="site-url">{url}</div>
                    <div class="enhancement-badges">"""
        
        # Enhancement badges
        if has_ai_eval:
            html_content += '<span class="enhancement-badge badge-ai">ü§ñ AI Enhanced</span>'
        if has_schema_enhanced:
            html_content += '<span class="enhancement-badge badge-schema">üèóÔ∏è Schema Enhanced</span>'
        if was_cached:
            html_content += '<span class="enhancement-badge badge-cache">üíæ Cached</span>'
            
        html_content += f"""
                    </div>
                </div>
                <div class="score-badge {score_class}">{fmt(score, 0)}</div>
            </div>
            
            <!-- Tab navig√°ci√≥ -->
            <div class="tabs">
                <button class="tab active" onclick="showTab(event, '{uid}', 'overview')">üìä √Åttekint√©s</button>
                <button class="tab" onclick="showTab(event, '{uid}', 'ai-metrics')">ü§ñ AI Metrik√°k</button>"""
        
        # Enhanced tabok hozz√°ad√°sa
        if has_ai_eval:
            html_content += f'<button class="tab" onclick="showTab(event, \'{uid}\', \'ai-enhanced\')">üöÄ AI Enhanced</button>'
        if has_schema_enhanced:
            html_content += f'<button class="tab" onclick="showTab(event, \'{uid}\', \'schema-enhanced\')">üèóÔ∏è Schema Enhanced</button>'
            
        html_content += f"""
                <button class="tab" onclick="showTab(event, '{uid}', 'content')">üìù Tartalom</button>
                <button class="tab" onclick="showTab(event, '{uid}', 'platforms')">üéØ Platformok</button>
                <button class="tab" onclick="showTab(event, '{uid}', 'fixes')">üîß Jav√≠t√°sok</button>
            </div>
            
            <!-- √Åttekint√©s tab -->
            <div id="{uid}-overview" class="tab-content active">
                <div class="metrics-grid">
                    <div class="metric-item">
                        <div class="metric-title">üìÑ Meta adatok</div>
                        <div class="metric-value">
"""
        
        # Meta adatok megjelen√≠t√©se (v√°ltozatlan)
        title = meta_data.get("title")
        description = meta_data.get("description")
        title_len = len(title) if title else 0
        desc_len = len(description) if description else 0
        title_status = "‚úÖ" if meta_data.get("title_optimal") else ("‚ö†Ô∏è" if title_len > 0 else "‚ùå")
        desc_status = "‚úÖ" if meta_data.get("description_optimal") else ("‚ö†Ô∏è" if desc_len > 0 else "‚ùå")
        
        html_content += f"""
                            Title: {title_status} {title_len} karakter<br>
                            Description: {desc_status} {desc_len} karakter<br>
                            OG Tags: {"‚úÖ" if meta_data.get('has_og_tags') else "‚ùå"}<br>
                            Twitter Card: {"‚úÖ" if meta_data.get('has_twitter_card') else "‚ùå"}
                        </div>
                    </div>
                    
                    <div class="metric-item">
                        <div class="metric-title">ü§ñ Crawlability</div>
                        <div class="metric-value">
                            Robots.txt: {"‚úÖ Enged√©lyezett" if site.get('robots_txt', {}).get('can_fetch') else "‚ùå Tiltott"}<br>
                            Sitemap: {"‚úÖ Van" if site.get('sitemap', {}).get('exists') else "‚ùå Nincs"}<br>
                            HTML m√©ret: {fmt(site.get('html_size_kb', 0), 1)} KB
                        </div>
                    </div>
                    
                    <div class="metric-item">
                        <div class="metric-title">üì± Mobile-friendly</div>
                        <div class="metric-value">
                            Viewport: {"‚úÖ" if mobile.get('has_viewport') else "‚ùå"}<br>
                            Responsive k√©pek: {"‚úÖ" if mobile.get('responsive_images') else "‚ùå"}
                        </div>
                    </div>
                    
                    <div class="metric-item {'ai-enhanced' if has_schema_enhanced else ''}">
                        <div class="metric-title">üèóÔ∏è Strukt√∫ra {'(Enhanced)' if has_schema_enhanced else ''}</div>
                        <div class="metric-value">
                            H1 elemek: {meta_data.get('h1_count', 0)}<br>
                            Heading hierarchia: {"‚úÖ" if meta_data.get('heading_hierarchy_valid') else "‚ö†Ô∏è"}<br>
                            Schema t√≠pusok: {sum(schema_data.get('count', {}).values())}<br>"""
        
        # Enhanced schema info
        if has_schema_enhanced:
            schema_score = schema_data.get('schema_completeness_score', 0)
            html_content += f"""
                            Schema Completeness: {fmt(schema_score, 1)}/100<br>
                            Google Validation: {"‚úÖ" if schema_data.get('google_validation', {}).get('is_valid') else "‚ùå"}"""
        
        html_content += """
                        </div>
                    </div>
                </div>
"""

        # AI Enhanced Score megjelen√≠t√©se ha van
        if has_ai_eval and ai_content_eval:
            ai_overall = ai_content_eval.get('overall_ai_score', 0)
            ai_platform_scores = ai_content_eval.get('ai_quality_scores', {})
            
            html_content += f"""
                <div class="ai-scores">
                    <h3>ü§ñ AI Enhanced Scores</h3>
                    <div class="ai-score-grid">
                        <div class="ai-score-item">
                            <div class="ai-score-value">{fmt(ai_overall, 1)}</div>
                            <div class="ai-score-label">Overall AI Score</div>
                        </div>"""
            
            for platform, score in ai_platform_scores.items():
                html_content += f"""
                        <div class="ai-score-item">
                            <div class="ai-score-value">{fmt(score, 1)}</div>
                            <div class="ai-score-label">{platform.title()}</div>
                        </div>"""
            
            html_content += """
                    </div>
                </div>"""
        
        # Chart container (v√°ltozatlan)
        html_content += f"""
                <div class="charts-row">
                    <div class="chart-container">
                        <canvas id="headingChart_{uid}"></canvas>
                    </div>
                    <div class="chart-container">
                        <canvas id="schemaChart_{uid}"></canvas>
                    </div>
                </div>
            </div>
"""
        
        # AI Enhanced tab (ha van)
        if has_ai_eval and ai_content_eval:
            html_content += f"""
            <!-- AI Enhanced tab -->
            <div id="{uid}-ai-enhanced" class="tab-content">
                <h3>üöÄ AI-alap√∫ tartalom √©rt√©kel√©s</h3>
                
                <div class="metrics-grid">
                    <div class="metric-item ai-enhanced">
                        <div class="metric-title">üéØ AI Pontsz√°mok</div>
                        <div class="metric-value">
                            Overall AI Score: {fmt(ai_content_eval.get('overall_ai_score', 0), 1)}/100<br>"""
            
            ai_platform_scores = ai_content_eval.get('ai_quality_scores', {})
            for platform, score in ai_platform_scores.items():
                html_content += f"                            {platform.title()}: {fmt(score, 1)}/100<br>"
            
            html_content += """
                        </div>
                    </div>"""
            
            # AI Readability ha van
            if ai_readability and not ai_readability.get('error'):
                html_content += f"""
                    <div class="metric-item ai-enhanced">
                        <div class="metric-title">üìñ AI Olvashat√≥s√°g</div>
                        <div class="metric-value">
                            Clarity: {fmt(ai_readability.get('clarity_score', 0), 1)}/100<br>
                            Engagement: {fmt(ai_readability.get('engagement_score', 0), 1)}/100<br>
                            Structure: {fmt(ai_readability.get('structure_score', 0), 1)}/100<br>
                            AI Friendliness: {fmt(ai_readability.get('ai_friendliness', 0), 1)}/100
                        </div>
                    </div>"""
            
            # AI Factual Check ha van
            if ai_factual and not ai_factual.get('error'):
                html_content += f"""
                    <div class="metric-item ai-enhanced">
                        <div class="metric-title">‚úÖ Faktualit√°s</div>
                        <div class="metric-value">
                            Factual Score: {fmt(ai_factual.get('factual_score', 0), 1)}/100<br>
                            Citations: {ai_factual.get('accuracy_indicators', {}).get('citations_present', 0)}<br>
                            Numbers with Units: {ai_factual.get('accuracy_indicators', {}).get('numbers_with_units', 0)}<br>
                            Confidence: {ai_factual.get('confidence_level', 'N/A')}
                        </div>
                    </div>"""
            
            html_content += "</div>"
            
            # AI javaslatok
            ai_recommendations = ai_content_eval.get('ai_recommendations', [])
            if ai_recommendations:
                html_content += "<h4>üí° AI Javaslatok:</h4><ul>"
                for rec in ai_recommendations:
                    html_content += f"<li>{rec}</li>"
                html_content += "</ul>"
            
            html_content += "</div>"
        
        # Schema Enhanced tab (ha van)
        if has_schema_enhanced:
            html_content += f"""
            <!-- Schema Enhanced tab -->
            <div id="{uid}-schema-enhanced" class="tab-content">
                <h3>üèóÔ∏è Enhanced Schema Valid√°ci√≥</h3>
                
                <div class="metrics-grid">"""
            
            google_validation = schema_data.get('google_validation', {})
            if google_validation:
                html_content += f"""
                    <div class="metric-item ai-enhanced">
                        <div class="metric-title">üîç Google Validation</div>
                        <div class="metric-value">
                            Valid: {"‚úÖ" if google_validation.get('is_valid') else "‚ùå"}<br>
                            Overall Score: {fmt(google_validation.get('overall_score', 0), 1)}/100<br>
                            Rich Results: {"‚úÖ" if google_validation.get('rich_results_eligible') else "‚ùå"}<br>
                            Schema Count: {google_validation.get('schema_count', 0)}
                        </div>
                    </div>"""
            
            # Schema aj√°nl√°sok
            recommendations = schema_data.get('recommendations', [])
            if recommendations:
                html_content += f"""
                    <div class="metric-item ai-enhanced">
                        <div class="metric-title">üí° Schema Aj√°nl√°sok</div>
                        <div class="metric-value">
                            Aj√°nl√°sok sz√°ma: {len(recommendations)}<br>"""
                
                for rec in recommendations[:3]:
                    if isinstance(rec, dict):
                        html_content += f"                            ‚Ä¢ {rec.get('schema_type', 'N/A')} ({rec.get('priority', 'medium')} priorit√°s)<br>"
                
                html_content += """
                        </div>
                    </div>"""
            
            # Effectiveness eredm√©nyek
            effectiveness = schema_data.get('effectiveness_analysis', [])
            if effectiveness:
                html_content += f"""
                    <div class="metric-item ai-enhanced">
                        <div class="metric-title">üìà Schema Effectiveness</div>
                        <div class="metric-value">"""
                
                for eff in effectiveness[:2]:
                    if isinstance(eff, dict):
                        html_content += f"                            {eff.get('schema_type', 'Schema')}: {fmt(eff.get('effectiveness_score', 0), 1)}/100<br>"
                
                html_content += """
                        </div>
                    </div>"""
            
            html_content += "</div></div>"
        
        # [Itt folytat√≥dnak a t√∂bbi tab-ok: AI Metrik√°k, Tartalom, Platformok, Jav√≠t√°sok - ezek v√°ltozatlanok]
        # A t√∂m√∂rs√©g kedv√©√©rt itt kihagyom a teljes implement√°ci√≥t, de ugyan√∫gy m≈±k√∂dnek mint az eredeti report.py-ban
        
        html_content += f"""
            <!-- Tov√°bbi tabok... (AI Metrik√°k, Tartalom, Platformok, Jav√≠t√°sok) -->
            <!-- [Az eredeti implement√°ci√≥ folytat√°sa] -->
        </div>"""

    # Footer (enhanced)
    current_year = datetime.now().year
    html_content += f"""
        <div class="footer">
            <p>¬© {current_year} {'Enhanced ' if is_enhanced else ''}GEO Analyzer | AI Readiness Report</p>
            <p style="margin-top: 10px; opacity: 0.8;">{'AI-Enhanced elemz√©s minden platform sz√°m√°ra' if is_enhanced else 'Teljes elemz√©s minden AI platform sz√°m√°ra'}</p>
        </div>
    </div>
    
    <script>
        function showTab(ev, siteId, tabName) {{
            const tabs = document.querySelectorAll(`#${{siteId}}-overview, #${{siteId}}-ai-metrics, #${{siteId}}-ai-enhanced, #${{siteId}}-schema-enhanced, #${{siteId}}-content, #${{siteId}}-platforms, #${{siteId}}-fixes`);
            tabs.forEach(tab => tab.classList.remove('active'));
            
            const targetTab = document.getElementById(`${{siteId}}-${{tabName}}`);
            if (targetTab) {{
                targetTab.classList.add('active');
            }}
            
            const tabButtons = ev.target.parentElement.querySelectorAll('.tab');
            tabButtons.forEach(btn => btn.classList.remove('active'));
            ev.target.classList.add('active');
        }}
"""

    # JavaScript chart gener√°l√°s (v√°ltozatlan az eredeti logik√°val)
    for idx, site in enumerate(data):
        if not isinstance(site, dict):
            continue
            
        url = site.get("url", "N/A")
        uid = f"site_{idx}_{re.sub(r'[^a-zA-Z0-9]', '_', url)}"
        
        meta_data = site.get("meta_and_headings", {})
        headings = meta_data.get("headings", {})
        
        schema_data = site.get("schema", {})
        schema_count = schema_data.get("count", {})
        
        # Headings chart
        if headings:
            heading_labels = list(headings.keys())
            heading_values = list(headings.values())
            
            html_content += f"""
    // Heading Chart - {uid}
    new Chart(document.getElementById('headingChart_{uid}'), {{
        type: 'bar',
        data: {{
            labels: {heading_labels},
            datasets: [{{
                label: 'Heading elemek sz√°ma',
                data: {heading_values},
                backgroundColor: [
                    'rgba(102, 126, 234, 0.8)',
                    'rgba(118, 75, 162, 0.8)',
                    'rgba(237, 100, 166, 0.8)',
                    'rgba(255, 159, 64, 0.8)',
                    'rgba(75, 192, 192, 0.8)',
                    'rgba(153, 102, 255, 0.8)'
                ],
                borderColor: 'rgba(102, 126, 234, 1)',
                borderWidth: 1
            }}]
        }},
        options: {{
            responsive: true,
            maintainAspectRatio: true,
            plugins: {{
                title: {{
                    display: true,
                    text: 'Heading Strukt√∫ra'
                }},
                legend: {{
                    display: false
                }}
            }},
            scales: {{
                y: {{
                    beginAtZero: true,
                    ticks: {{
                        stepSize: 1
                    }}
                }}
            }}
        }}
    }});
"""
        
        # Schema chart
        if schema_count and any(v > 0 for v in schema_count.values()):
            filtered_schema = {k: v for k, v in schema_count.items() if v > 0}
            
            html_content += f"""
    // Schema Chart - {uid}
    const schemaCounts_{uid.replace('-', '_')} = {json.dumps(filtered_schema)};
    new Chart(document.getElementById('schemaChart_{uid}'), {{
        type: 'bar',
        data: {{
            labels: Object.keys(schemaCounts_{uid.replace('-', '_')}),
            datasets: [{{
                label: 'Schema t√≠pusok',
                data: Object.values(schemaCounts_{uid.replace('-', '_')}),
                backgroundColor: [
                    'rgba(255, 99, 132, 0.8)',
                    'rgba(54, 162, 235, 0.8)',
                    'rgba(255, 206, 86, 0.8)',
                    'rgba(75, 192, 192, 0.8)',
                    'rgba(153, 102, 255, 0.8)',
                    'rgba(255, 159, 64, 0.8)',
                    'rgba(231, 76, 60, 0.8)'
                ],
                borderColor: 'white',
                borderWidth: 2
            }}]
        }},
        options: {{
            responsive: true,
            maintainAspectRatio: true,
            plugins: {{
                title: {{
                    display: true,
                    text: 'Schema t√≠pusok'
                }},
                legend: {{
                    display: false
                }}
            }},
            scales: {{
                y: {{
                    beginAtZero: true,
                    ticks: {{
                        stepSize: 1
                    }}
                }}
            }}
        }}
    }});
"""

    html_content += """
    </script>
</body>
</html>
"""

    # HTML f√°jl ment√©se
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(html_content)

    report_type = "Enhanced" if is_enhanced else "Standard"
    print(f"‚úÖ {report_type} HTML jelent√©s elk√©sz√ºlt: {output_file}")
    print(f"üìä Elemzett oldalak sz√°ma: {len(data)}")
    print(f"‚≠ê √Åtlagos AI-readiness score: {avg_score:.1f}/100")
    if is_enhanced:
        print(f"ü§ñ AI Enhanced eredm√©nyek: {ai_enhanced_count}")
        print(f"üèóÔ∏è Schema Enhanced eredm√©nyek: {schema_enhanced_count}")



##############################################

def generate_comprehensive_report(self, analysis_results: List[Dict], 
                                    report_type: str = 'executive',
                                    competitor_data: Optional[List[Dict]] = None) -> Dict:
        """√Åtfog√≥ jelent√©s gener√°l√°sa - Enhanced verzi√≥"""
        
        if not analysis_results:
            return {"error": "Nincs adat az elemz√©shez"}
        
        # Enhanced adatok felismer√©se
        is_enhanced = any(
            result.get('ai_content_evaluation') or 
            result.get('schema', {}).get('validation_status') == 'enhanced'
            for result in analysis_results if isinstance(result, dict)
        )
        
        # Alapstatisztik√°k (enhanced)
        base_stats = self._calculate_enhanced_base_statistics(analysis_results)
        
        # Trendek elemz√©se (enhanced)
        trends = self._analyze_enhanced_trends(analysis_results)
        
        # Probl√©m√°k azonos√≠t√°sa (enhanced)
        issues = self._identify_enhanced_common_issues(analysis_results)
        
        # Lehet≈ës√©gek felt√°r√°sa (enhanced)
        opportunities = self._identify_enhanced_opportunities(analysis_results)
        
        # Specifikus jelent√©s gener√°l√°sa
        if report_type in self.report_templates:
            specific_report = self.report_templates[report_type](
                analysis_results, base_stats, trends, issues, opportunities, competitor_data
            )
        else:
            specific_report = {"error": f"Ismeretlen jelent√©s t√≠pus: {report_type}"}
        
        return {
            "report_type": report_type,
            "enhanced_analysis": is_enhanced,
            "generated_at": datetime.now().isoformat(),
            "summary": base_stats,
            "trends": trends,
            "issues": issues,
            "opportunities": opportunities,
            "detailed_report": specific_report,
            "recommendations": self._generate_enhanced_strategic_recommendations(base_stats, trends, issues, is_enhanced)
        }
    
    def _calculate_enhanced_base_statistics(self, results: List[Dict]) -> Dict:
        """Enhanced alapstatisztik√°k sz√°m√≠t√°sa"""
        
        valid_results = [r for r in results if 'ai_readiness_score' in r]
        
        if not valid_results:
            return {"error": "Nincs √©rv√©nyes AI readiness score"}
        
        # Enhanced adatok azonos√≠t√°sa
        ai_enhanced_results = [r for r in valid_results if r.get('ai_content_evaluation')]
        schema_enhanced_results = [r for r in valid_results if r.get('schema', {}).get('validation_status') == 'enhanced']
        cached_results = [r for r in valid_results if r.get('cached')]
        
        scores = [r['ai_readiness_score'] for r in valid_results]
        
        # AI Enhanced pontsz√°mok
        ai_enhanced_scores = []
        if ai_enhanced_results:
            ai_enhanced_scores = [r['ai_content_evaluation'].get('overall_ai_score', 0) for r in ai_enhanced_results]
        
        # Schema Enhanced pontsz√°mok
        schema_enhanced_scores = []
        if schema_enhanced_results:
            schema_enhanced_scores = [r['schema'].get('schema_completeness_score', 0) for r in schema_enhanced_results]
        
        # Platform specifikus pontsz√°mok (enhanced)
        platform_scores = {}
        ai_platform_scores = {}
        
        for result in valid_results:
            platform_data = result.get('platform_analysis', {})
            for platform, data in platform_data.items():
                if platform != 'summary' and isinstance(data, dict):
                    # Hagyom√°nyos score
                    score = data.get('compatibility_score', 0)
                    if platform not in platform_scores:
                        platform_scores[platform] = []
                    platform_scores[platform].append(score)
                    
                    # AI enhanced score
                    ai_score = data.get('hybrid_compatibility_score', score)
                    if platform not in ai_platform_scores:
                        ai_platform_scores[platform] = []
                    ai_platform_scores[platform].append(ai_score)
        
        # Tartalom √©s technikai metrik√°k (enhanced)
        content_metrics = self._analyze_enhanced_content_metrics(valid_results)
        technical_metrics = self._analyze_enhanced_technical_metrics(valid_results)
        
        # AI metrik√°k
        ai_metrics = {}
        if ai_enhanced_results:
            ai_metrics = {
                "ai_enhanced_count": len(ai_enhanced_results),
                "ai_enhanced_percentage": round((len(ai_enhanced_results) / len(valid_results)) * 100, 1),
                "average_ai_score": round(statistics.mean(ai_enhanced_scores), 1) if ai_enhanced_scores else 0,
                "ai_score_distribution": self._score_distribution(ai_enhanced_scores) if ai_enhanced_scores else {}
            }
        
        # Schema Enhanced metrik√°k
        schema_metrics = {}
        if schema_enhanced_results:
            schema_metrics = {
                "schema_enhanced_count": len(schema_enhanced_results),
                "schema_enhanced_percentage": round((len(schema_enhanced_results) / len(valid_results)) * 100, 1),
                "average_schema_score": round(statistics.mean(schema_enhanced_scores), 1) if schema_enhanced_scores else 0,
                "schema_score_distribution": self._score_distribution(schema_enhanced_scores) if schema_enhanced_scores else {}
            }
        
        return {
            "total_sites": len(results),
            "analyzed_sites": len(valid_results),
            "ai_readiness": {
                "average": round(statistics.mean(scores), 1),
                "median": round(statistics.median(scores), 1),
                "std_dev": round(statistics.stdev(scores) if len(scores) > 1 else 0, 1),
                "min": min(scores),
                "max": max(scores),
                "distribution": self._score_distribution(scores)
            },
            "enhancement_statistics": {
                "ai_enhanced": ai_metrics,
                "schema_enhanced": schema_metrics,
                "cached_results": len(cached_results),
                "cache_hit_rate": round((len(cached_results) / len(valid_results)) * 100, 1) if valid_results else 0
            },
            "platform_performance": {
                platform: {
                    "average": round(statistics.mean(score_list), 1),
                    "best": max(score_list),
                    "worst": min(score_list)
                } for platform, score_list in platform_scores.items()
            },
            "ai_platform_performance": {
                platform: {
                    "average": round(statistics.mean(score_list), 1),
                    "best": max(score_list),
                    "worst": min(score_list),
                    "improvement": round(statistics.mean(score_list) - statistics.mean(platform_scores.get(platform, [0])), 1)
                } for platform, score_list in ai_platform_scores.items()
            },
            "content_quality": content_metrics,
            "technical_health": technical_metrics,
            "performance_categories": self._categorize_performance(scores)
        }
    
    def _analyze_enhanced_content_metrics(self, results: List[Dict]) -> Dict:
        """Enhanced tartalom metrik√°k elemz√©se"""
        content_scores = []
        ai_content_scores = []
        factual_scores = []
        
        for result in results:
            content_quality = result.get('content_quality', {})
            if content_quality and not content_quality.get('error'):
                overall_score = content_quality.get('overall_quality_score', 0)
                content_scores.append(overall_score)
            
            # AI content evaluation scores
            ai_content_eval = result.get('ai_content_evaluation', {})
            if ai_content_eval and not ai_content_eval.get('error'):
                ai_overall = ai_content_eval.get('overall_ai_score', 0)
                ai_content_scores.append(ai_overall)
            
            # Factual accuracy scores
            ai_factual = result.get('ai_factual_check', {})
            if ai_factual and not ai_factual.get('error'):
                factual_score = ai_factual.get('factual_score', 0)
                factual_scores.append(factual_score)
        
        base_metrics = {
            "average_content_score": round(statistics.mean(content_scores), 1) if content_scores else 0,
            "content_distribution": self._score_distribution(content_scores) if content_scores else {},
            "top_content_areas": self._identify_content_strengths(results),
            "content_gaps": self._identify_content_gaps(results)
        }
        
        # Enhanced metrik√°k hozz√°ad√°sa
        if ai_content_scores:
            base_metrics["ai_content_evaluation"] = {
                "average_ai_content_score": round(statistics.mean(ai_content_scores), 1),
                "ai_content_distribution": self._score_distribution(ai_content_scores),
                "ai_vs_traditional_improvement": round(statistics.mean(ai_content_scores) - statistics.mean(content_scores), 1) if content_scores else 0
            }
        
        if factual_scores:
            base_metrics["factual_analysis"] = {
                "average_factual_score": round(statistics.mean(factual_scores), 1),
                "factual_distribution": self._score_distribution(factual_scores),
                "high_factual_accuracy_sites": len([s for s in factual_scores if s >= 70])
            }
        
        return base_metrics
    
    def _analyze_enhanced_technical_metrics(self, results: List[Dict]) -> Dict:
        """Enhanced technikai metrik√°k elemz√©se"""
        
        mobile_ready = sum(1 for r in results if r.get('mobile_friendly', {}).get('has_viewport'))
        has_sitemap = sum(1 for r in results if r.get('sitemap', {}).get('exists'))
        robots_ok = sum(1 for r in results if r.get('robots_txt', {}).get('can_fetch'))
        
        # Enhanced schema metrik√°k
        schema_enhanced = sum(1 for r in results if r.get('schema', {}).get('validation_status') == 'enhanced')
        google_validated = sum(1 for r in results if r.get('schema', {}).get('google_validation', {}).get('is_valid'))
        
        total = len(results)
        
        base_metrics = {
            "mobile_readiness": round((mobile_ready / total) * 100, 1),
            "sitemap_coverage": round((has_sitemap / total) * 100, 1),
            "robots_compliance": round((robots_ok / total) * 100, 1),
            "technical_health_score": round(((mobile_ready + has_sitemap + robots_ok) / (total * 3)) * 100, 1)
        }
        
        # Enhanced schema metrik√°k
        if any(r.get('schema', {}).get('validation_status') == 'enhanced' for r in results):
            base_metrics["schema_enhancement"] = {
                "schema_enhanced_percentage": round((schema_enhanced / total) * 100, 1),
                "google_validation_rate": round((google_validated / total) * 100, 1),
                "schema_improvement_opportunity": total - schema_enhanced
            }
        
        return base_metrics
    
    def _analyze_enhanced_trends(self, results: List[Dict]) -> Dict:
        """Enhanced trendek elemz√©se"""
        
        base_trends = {
            "schema_adoption": self._analyze_schema_trends(results),
            "mobile_readiness": self._analyze_mobile_trends(results),
            "content_quality_trends": self._analyze_content_trends(results),
            "ai_optimization_maturity": self._analyze_ai_maturity(results)
        }
        
        # Enhanced trend analysis
        ai_enhanced_results = [r for r in results if r.get('ai_content_evaluation')]
        if ai_enhanced_results:
            base_trends["ai_enhancement_adoption"] = {
                "adoption_rate": round((len(ai_enhanced_results) / len(results)) * 100, 1),
                "ai_score_trend": "positive" if len(ai_enhanced_results) > len(results) * 0.5 else "needs_improvement",
                "platform_ai_improvements": self._analyze_platform_ai_improvements(results)
            }
        
        # Schema enhancement trends
        schema_enhanced_results = [r for r in results if r.get('schema', {}).get('validation_status') == 'enhanced']
        if schema_enhanced_results:
            base_trends["schema_enhancement_trends"] = {
                "enhancement_rate": round((len(schema_enhanced_results) / len(results)) * 100, 1),
                "google_validation_success": sum(1 for r in schema_enhanced_results if r.get('schema', {}).get('google_validation', {}).get('is_valid')),
                "schema_recommendation_utilization": self._analyze_schema_recommendation_usage(schema_enhanced_results)
            }
        
        return base_trends
    
    def _identify_enhanced_common_issues(self, results: List[Dict]) -> List[Dict]:
        """Enhanced gyakori probl√©m√°k azonos√≠t√°sa"""
        
        # Alapvet≈ë probl√©m√°k (v√°ltozatlan logika)
        issues = self._identify_common_issues(results)
        
        total_sites = len(results)
        
        # Enhanced specifikus probl√©m√°k
        
        # AI enhancement hi√°nya
        ai_enhanced_count = len([r for r in results if r.get('ai_content_evaluation')])
        if ai_enhanced_count < total_sites * 0.3:  # Ha kevesebb mint 30% AI enhanced
            issues.append({
                "type": "enhancement_opportunity",
                "category": "AI Enhancement",
                "issue": "Alacsony AI enhancement ar√°ny",
                "affected_sites": total_sites - ai_enhanced_count,
                "percentage": round(((total_sites - ai_enhanced_count) / total_sites) * 100, 1),
                "impact": "Elmarad√°s AI-optimaliz√°lt tartalom ter√©n",
                "priority": 3
            })
        
        # Schema enhancement hi√°nya
        schema_enhanced_count = len([r for r in results if r.get('schema', {}).get('validation_status') == 'enhanced'])
        if schema_enhanced_count < total_sites * 0.4:  # Ha kevesebb mint 40% schema enhanced
            issues.append({
                "type": "enhancement_opportunity", 
                "category": "Schema Enhancement",
                "issue": "Alacsony schema enhancement ar√°ny",
                "affected_sites": total_sites - schema_enhanced_count,
                "percentage": round(((total_sites - schema_enhanced_count) / total_sites) * 100, 1),
                "impact": "Gyenge struktur√°lt adat optimaliz√°l√°s",
                "priority": 4
            })
        
        # Google validation probl√©m√°k
        google_validation_failures = sum(1 for r in results 
                                       if r.get('schema', {}).get('google_validation', {}).get('is_valid') == False)
        if google_validation_failures > total_sites * 0.2:
            issues.append({
                "type": "high",
                "category": "Schema Validation",
                "issue": "Google Schema valid√°ci√≥s hib√°k",
                "affected_sites": google_validation_failures,
                "percentage": round((google_validation_failures / total_sites) * 100, 1),
                "impact": "Rich Results megjelen√©s akad√°lyozva",
                "priority": 2
            })
        
        # AI platform specifikus probl√©m√°k
        for platform in ['chatgpt', 'claude', 'gemini', 'bing_chat']:
            low_ai_scores = sum(1 for r in results 
                              if r.get('platform_analysis', {}).get(platform, {}).get('hybrid_compatibility_score', 100) < 50)
            if low_ai_scores > total_sites * 0.3:
                issues.append({
                    "type": "medium",
                    "category": f"{platform.title()} Optimization",
                    "issue": f"Alacsony {platform.title()} AI compatibility",
                    "affected_sites": low_ai_scores,
                    "percentage": round((low_ai_scores / total_sites) * 100, 1),
                    "impact": f"Gyenge {platform.title()} platform teljes√≠tm√©ny",
                    "priority": 5
                })
        
        return sorted(issues, key=lambda x: x['priority'])
    
    def _identify_enhanced_opportunities(self, results: List[Dict]) -> List[Dict]:
        """Enhanced lehet≈ës√©gek azonos√≠t√°sa"""
        
        # Alapvet≈ë lehet≈ës√©gek
        opportunities = self._identify_opportunities(results)
        
        # AI enhancement lehet≈ës√©gek
        ai_opportunities = self._analyze_ai_enhancement_opportunities(results)
        opportunities.extend(ai_opportunities)
        
        # Schema enhancement lehet≈ës√©gek  
        schema_opportunities = self._analyze_schema_enhancement_opportunities(results)
        opportunities.extend(schema_opportunities)
        
        # Platform AI optimaliz√°l√°si lehet≈ës√©gek
        platform_opportunities = self._analyze_platform_ai_opportunities(results)
        opportunities.extend(platform_opportunities)
        
        return opportunities
    
    def _analyze_ai_enhancement_opportunities(self, results: List[Dict]) -> List[Dict]:
        """AI enhancement lehet≈ës√©gek elemz√©se"""
        opportunities = []
        
        non_ai_enhanced = [r for r in results if not r.get('ai_content_evaluation')]
        
        if non_ai_enhanced:
            # Magas potenci√°l√∫ oldalak AI enhancement-re
            high_potential = [r for r in non_ai_enhanced if r.get('ai_readiness_score', 0) >= 60]
            
            if high_potential:
                opportunities.append({
                    "type": "ai_enhancement",
                    "priority": "high",
                    "opportunity": "AI Content Evaluation implement√°l√°s",
                    "description": f"{len(high_potential)} oldal magas potenci√°llal AI enhancement-re",
                    "impact_level": "high",
                    "estimated_score_improvement": 15,
                    "affected_sites": len(high_potential),
                    "implementation_effort": "medium"
                })
        
        # Factual accuracy jav√≠t√°si lehet≈ës√©gek
        low_factual_accuracy = [r for r in results 
                              if r.get('ai_factual_check', {}).get('factual_score', 100) < 50]
        
        if low_factual_accuracy:
            opportunities.append({
                "type": "factual_improvement",
                "priority": "medium", 
                "opportunity": "Faktualit√°s jav√≠t√°s",
                "description": f"{len(low_factual_accuracy)} oldal alacsony faktualit√°si pontsz√°mmal",
                "impact_level": "medium",
                "estimated_score_improvement": 10,
                "affected_sites": len(low_factual_accuracy),
                "implementation_effort": "low"
            })
        
        return opportunities
    
    def _analyze_schema_enhancement_opportunities(self, results: List[Dict]) -> List[Dict]:
        """Schema enhancement lehet≈ës√©gek elemz√©se"""
        opportunities = []
        
        # Schema recommendation utilization
        schema_recommendations = []
        for result in results:
            recs = result.get('schema', {}).get('recommendations', [])
            schema_recommendations.extend(recs)
        
        if schema_recommendations:
            high_impact_recs = [r for r in schema_recommendations 
                              if isinstance(r, dict) and r.get('estimated_impact', 0) >= 80]
            
            if high_impact_recs:
                opportunities.append({
                    "type": "schema_implementation",
                    "priority": "high",
                    "opportunity": "Magas hat√°s√∫ Schema implement√°l√°s", 
                    "description": f"{len(high_impact_recs)} magas hat√°s√∫ schema aj√°nl√°s el√©rhet≈ë",
                    "impact_level": "high",
                    "estimated_score_improvement": 20,
                    "affected_sites": len(set(r.get('url', '') for r in results if r.get('schema', {}).get('recommendations'))),
                    "implementation_effort": "medium"
                })
        
        # Google validation fejleszt√©si lehet≈ës√©gek
        validation_failures = [r for r in results 
                             if r.get('schema', {}).get('google_validation', {}).get('is_valid') == False]
        
        if validation_failures:
            opportunities.append({
                "type": "schema_validation",
                "priority": "medium",
                "opportunity": "Google Schema valid√°ci√≥ jav√≠t√°s",
                "description": f"{len(validation_failures)} oldal schema valid√°ci√≥s hib√°kkal",
                "impact_level": "medium", 
                "estimated_score_improvement": 12,
                "affected_sites": len(validation_failures),
                "implementation_effort": "low"
            })
        
        return opportunities
    
    def _analyze_platform_ai_opportunities(self, results: List[Dict]) -> List[Dict]:
        """Platform AI optimaliz√°l√°si lehet≈ës√©gek"""
        opportunities = []
        
        # Platform specifikus AI fejleszt√©si lehet≈ës√©gek
        for platform in ['chatgpt', 'claude', 'gemini', 'bing_chat']:
            platform_scores = []
            ai_enhanced_scores = []
            
            for result in results:
                platform_data = result.get('platform_analysis', {}).get(platform, {})
                if platform_data:
                    traditional_score = platform_data.get('compatibility_score', 0)
                    ai_enhanced_score = platform_data.get('hybrid_compatibility_score', traditional_score)
                    
                    platform_scores.append(traditional_score)
                    ai_enhanced_scores.append(ai_enhanced_score)
            
            if platform_scores:
                avg_traditional = statistics.mean(platform_scores)
                avg_ai_enhanced = statistics.mean(ai_enhanced_scores) 
                
                improvement_potential = avg_ai_enhanced - avg_traditional
                
                if improvement_potential > 5:  # Jelent≈ës javul√°si potenci√°l
                    opportunities.append({
                        "type": "platform_ai_optimization",
                        "priority": "medium",
                        "opportunity": f"{platform.title()} AI optimization",
                        "description": f"AI enhancement {improvement_potential:.1f} pontos javul√°st hozhat",
                        "impact_level": "medium",
                        "estimated_score_improvement": improvement_potential,
                        "affected_sites": len(platform_scores),
                        "implementation_effort": "medium",
                        "platform": platform
                    })
        
        return opportunities
    
    def _generate_enhanced_strategic_recommendations(self, stats: Dict, trends: Dict, 
                                                   issues: List[Dict], is_enhanced: bool) -> List[Dict]:
        """Enhanced strat√©giai aj√°nl√°sok gener√°l√°sa"""
        
        recommendations = self._generate_strategic_recommendations(stats, trends, issues)
        
        if not is_enhanced:
            return recommendations
        
        # Enhanced specifikus aj√°nl√°sok
        
        # AI Enhancement priorit√°s
        enhancement_stats = stats.get('enhancement_statistics', {})
        ai_enhanced_pct = enhancement_stats.get('ai_enhanced', {}).get('ai_enhanced_percentage', 0)
        
        if ai_enhanced_pct < 50:
            recommendations.insert(0, {
                "type": "ai_enhancement_strategy",
                "priority": "critical",
                "recommendation": "AI Enhancement kiterjeszt√©se",
                "rationale": f"Csak {ai_enhanced_pct}% AI enhanced - jelent≈ës elmarad√°s",
                "actions": [
                    "AI Content Evaluation bekapcsol√°sa minden oldalon",
                    "Factual accuracy ellen≈ërz√©s implement√°l√°sa", 
                    "Platform-specifikus AI optimaliz√°l√°s",
                    "AI-alap√∫ tartalom min≈ës√©g jav√≠t√°s"
                ],
                "timeline": "2-3 h√≥nap",
                "expected_impact": "25-35 pontos score n√∂veked√©s",
                "investment_level": "medium"
            })
        
        # Schema Enhancement priorit√°s
        schema_enhanced_pct = enhancement_stats.get('schema_enhanced', {}).get('schema_enhanced_percentage', 0)
        
        if schema_enhanced_pct < 60:
            recommendations.insert(1, {
                "type": "schema_enhancement_strategy", 
                "priority": "high",
                "recommendation": "Schema Enhancement kamp√°ny",
                "rationale": f"Csak {schema_enhanced_pct}% schema enhanced - struktur√°lt adat hi√°ny",
                "actions": [
                    "Google Rich Results valid√°ci√≥ minden schema-ra",
                    "Dinamikus schema aj√°nl√°sok implement√°l√°sa",
                    "Schema effectiveness m√©r√©s bevezet√©se",
                    "Magas hat√°s√∫ schema t√≠pusok priorit√°sa"
                ],
                "timeline": "1-2 h√≥nap",
                "expected_impact": "15-25 pontos schema score n√∂veked√©s",
                "investment_level": "low"
            })
        
        # Platform AI optimization
        ai_platform_performance = stats.get('ai_platform_performance', {})
        if ai_platform_performance:
            weakest_platform = min(ai_platform_performance.items(), key=lambda x: x[1]['average'])
            if weakest_platform[1]['average'] < 60:
                recommendations.append({
                    "type": "platform_ai_optimization",
                    "priority": "medium",
                    "recommendation": f"{weakest_platform[0].title()} AI optimization f√≥kusz",
                    "rationale": f"Leggyeng√©bb AI platform teljes√≠tm√©ny: {weakest_platform[1]['average']:.1f}",
                    "actions": self._get_platform_ai_actions(weakest_platform[0]),
                    "timeline": "3-4 h√©t",
                    "expected_impact": f"+{min(25, 70-weakest_platform[1]['average'])} pontos platform javul√°s",
                    "investment_level": "low"
                })
        
        return recommendations
    
    def _get_platform_ai_actions(self, platform: str) -> List[str]:
        """Platform specifikus AI optimaliz√°l√°si akci√≥k"""
        platform_ai_actions = {
            "chatgpt": [
                "AI-assisted step-by-step tartalom gener√°l√°s",
                "Interactive Q&A blokkok AI optimaliz√°l√°ssal",
                "ML-alap√∫ list struktur√°l√°s",
                "AI content scoring feedback loop"
            ],
            "claude": [
                "AI-enhanced kontextu√°lis tartalom b≈ëv√≠t√©s",
                "Automated citation √©s source linking",
                "AI-driven technical depth analysis",
                "Contextual AI content recommendations"
            ],
            "gemini": [
                "AI-assisted multim√©dia tartalom optimaliz√°l√°s",
                "Automated schema generation √©s validation",
                "AI-driven freshness content updates",
                "ML-based structured data enhancement"
            ],
            "bing_chat": [
                "AI-enhanced external reference optimization",
                "Automated source credibility scoring",
                "AI-driven time-sensitive content flagging",
                "ML-based citation quality improvement"
            ]
        }
        
        return platform_ai_actions.get(platform, ["√Åltal√°nos AI optimaliz√°l√°s"])
    
    def _analyze_platform_ai_improvements(self, results: List[Dict]) -> Dict:
        """Platform AI fejleszt√©sek elemz√©se"""
        improvements = {}
        
        for platform in ['chatgpt', 'claude', 'gemini', 'bing_chat']:
            traditional_scores = []
            ai_scores = []
            
            for result in results:
                platform_data = result.get('platform_analysis', {}).get(platform, {})
                if platform_data:
                    traditional = platform_data.get('compatibility_score', 0)
                    ai_enhanced = platform_data.get('hybrid_compatibility_score', traditional)
                    
                    traditional_scores.append(traditional)
                    ai_scores.append(ai_enhanced)
            
            if traditional_scores and ai_scores:
                avg_improvement = statistics.mean(ai_scores) - statistics.mean(traditional_scores)
                improvements[platform] = {
                    "average_improvement": round(avg_improvement, 1),
                    "improvement_rate": round((avg_improvement / statistics.mean(traditional_scores)) * 100, 1) if statistics.mean(traditional_scores) > 0 else 0,
                    "sites_improved": len([i for i in range(len(ai_scores)) if ai_scores[i] > traditional_scores[i]])
                }
        
        return improvements
    
    def _analyze_schema_recommendation_usage(self, schema_enhanced_results: List[Dict]) -> Dict:
        """Schema aj√°nl√°s felhaszn√°l√°s elemz√©se"""
        total_recommendations = 0
        high_impact_recommendations = 0
        implemented_schemas = 0
        
        for result in schema_enhanced_results:
            recommendations = result.get('schema', {}).get('recommendations', [])
            total_recommendations += len(recommendations)
            
            high_impact_recs = [r for r in recommendations 
                              if isinstance(r, dict) and r.get('estimated_impact', 0) >= 80]
            high_impact_recommendations += len(high_impact_recs)
            
            # Schema count as proxy for implementation
            schema_count = sum(result.get('schema', {}).get('count', {}).values())
            if schema_count > 0:
                implemented_schemas += 1
        
        return {
            "total_recommendations": total_recommendations,
            "high_impact_recommendations": high_impact_recommendations,
            "implementation_rate": round((implemented_schemas / len(schema_enhanced_results)) * 100, 1) if schema_enhanced_results else 0,
            "high_impact_ratio": round((high_impact_recommendations / total_recommendations) * 100, 1) if total_recommendations > 0 else 0
        }



#################################

class MultiPlatformGEOAnalyzer:
    """Multi-platform GEO elemz≈ë f≈ëoszt√°ly - AI-enhanced verzi√≥"""
    
    def __init__(self, ai_evaluator=None, cache_manager=None):
        self.platforms = {
            'chatgpt': ChatGPTOptimizer(),
            'claude': ClaudeOptimizer(),
            'gemini': GeminiOptimizer(),
            'bing_chat': BingChatOptimizer()
        }
        self.ai_evaluator = ai_evaluator
        self.cache_manager = cache_manager
        self.ml_scorer = MLPlatformScorer() if self._ml_available() else None


############################################