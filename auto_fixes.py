import re
import json
from typing import Dict, List, Optional, Tuple
from urllib.parse import urlparse
from bs4 import BeautifulSoup
from string import Template


class AutoFixGenerator:
    """Automatikus jav√≠t√°si javaslatok gener√°l√°sa"""
    
    def __init__(self):
        self.meta_templates = {
            "title": {
                "template": "<title>{title}</title>",
                "optimal_length": (30, 60),
                "examples": [
                    "Professzion√°lis SEO szolg√°ltat√°sok - Weboldaloptimaliz√°l√°s",
                    "Python fejleszt√©s - Egyedi szoftverek √©s alkalmaz√°sok"
                ]
            },
            "description": {
                "template": '<meta name="description" content="{description}">',
                "optimal_length": (120, 160),
                "examples": [
                    "Professzion√°lis SEO √©s weboldaloptimaliz√°l√°s szolg√°ltat√°sok. N√∂veld weboldalad l√°togatotts√°g√°t √©s keres≈ëmotoros rangsorol√°sodat szak√©rt≈ë csapatunkkal.",
                    "Python alap√∫ egyedi szoftverek √©s webalkalmaz√°sok fejleszt√©se. API integr√°ci√≥, automatiz√°l√°s √©s adatelemz√©s professzion√°lis megold√°sokkal."
                ]
            }
        }
        
        self.schema_templates = {
            "organization": Template("""{
  "@context": "https://schema.org",
  "@type": "Organization",
  "name": "$company_name",
  "url": "$website_url",
  "logo": "$logo_url",
  "description": "$company_description",
  "address": {
    "@type": "PostalAddress",
    "streetAddress": "$street_address",
    "addressLocality": "$city",
    "addressCountry": "$country"
  },
  "contactPoint": {
    "@type": "ContactPoint",
    "telephone": "$phone",
    "contactType": "customer service"
  }
}"""),
            
            "faq": Template("""{
  "@context": "https://schema.org",
  "@type": "FAQPage",
  "mainEntity": [
    {
      "@type": "Question",
      "name": "$question",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "$answer"
      }
    }
  ]
}"""),
            
            "article": Template("""{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "$headline",
  "author": {
    "@type": "Person",
    "name": "$author_name"
  },
  "datePublished": "$publish_date",
  "dateModified": "$modified_date",
  "description": "$article_description",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "$article_url"
  }
}"""),
            
            "howto": Template("""{
  "@context": "https://schema.org",
  "@type": "HowTo",
  "name": "$howto_title",
  "description": "$howto_description",
  "step": [
    {
      "@type": "HowToStep",
      "name": "$step_name",
      "text": "$step_description"
    }
  ]
}""")
        }
    
    def generate_all_fixes(self, analysis_result: Dict, url: str) -> Dict:
        """√ñsszes automatikus jav√≠t√°s gener√°l√°sa - JAV√çTVA"""
        
        # JAV√çT√ÅS: Ellen≈ërizz√ºk, hogy van-e √©rv√©nyes analysis_result
        if not analysis_result or not isinstance(analysis_result, dict):
            return {
                "error": "Nincs elemz√©si adat",
                "critical_fixes": [],
                "seo_improvements": [],
                "schema_suggestions": [],
                "content_optimizations": [],
                "technical_fixes": [],
                "ai_readiness_fixes": [],
                "implementation_guide": {},
                "prioritized_actions": []
            }
        
        try:
            fixes = {
                "critical_fixes": self._generate_critical_fixes(analysis_result, url),
                "seo_improvements": self._generate_seo_improvements(analysis_result, url),
                "schema_suggestions": self._generate_schema_fixes(analysis_result, url),
                "content_optimizations": self._generate_content_fixes(analysis_result),
                "technical_fixes": self._generate_technical_fixes(analysis_result),
                "ai_readiness_fixes": self._generate_ai_fixes(analysis_result),
                "implementation_guide": self._create_implementation_guide()
            }
            
            # Priorit√°s szerinti rendez√©s
            fixes["prioritized_actions"] = self._prioritize_fixes(fixes)
            
            return fixes
            
        except Exception as e:
            # Ha b√°rmilyen hiba van, visszaadjuk az alap strukt√∫r√°t
            return {
                "error": str(e),
                "critical_fixes": [],
                "seo_improvements": [],
                "schema_suggestions": [],
                "content_optimizations": [],
                "technical_fixes": [],
                "ai_readiness_fixes": [],
                "implementation_guide": self._create_implementation_guide(),
                "prioritized_actions": []
            }
    
    def _generate_critical_fixes(self, analysis: Dict, url: str) -> List[Dict]:
        """Kritikus hib√°k jav√≠t√°sa - JAV√çTVA"""
        critical_fixes = []
        
        meta_data = analysis.get("meta_and_headings", {})
        
        # JAV√çT√ÅS: Biztons√°gos title kezel√©s
        title = meta_data.get("title")
        if not title:  # Ha None vagy √ºres string
            domain = urlparse(url).netloc
            suggested_title = self._suggest_title_from_domain(domain)
            
            critical_fixes.append({
                "issue": "Hi√°nyz√≥ title tag",
                "severity": "critical",
                "impact": "SEO √©s AI rangsorol√°s drasztikus roml√°sa",
                "fix_code": f'<title>{suggested_title}</title>',
                "explanation": "A title tag a legfontosabb SEO elem",
                "estimated_time": "2 perc",
                "implementation": "head szekci√≥ els≈ë eleme legyen"
            })
        
        # JAV√çT√ÅS: Biztons√°gos description kezel√©s
        description = meta_data.get("description")
        if not description:  # Ha None vagy √ºres string
            suggested_description = self._suggest_description_from_domain(urlparse(url).netloc)
            
            critical_fixes.append({
                "issue": "Hi√°nyz√≥ meta description",
                "severity": "critical",
                "impact": "Alacsony CTR a keres≈ëkben",
                "fix_code": f'<meta name="description" content="{suggested_description}">',
                "explanation": "Meta description befoly√°solja a kattint√°si ar√°nyt",
                "estimated_time": "3 perc",
                "implementation": "head szekci√≥ban a title ut√°n"
            })
        
        # Hi√°nyz√≥ H1
        if meta_data.get("h1_count", 0) == 0:
            # JAV√çT√ÅS: Biztons√°gos title haszn√°lat H1 javaslatra
            suggested_h1 = title if title else self._suggest_title_from_domain(urlparse(url).netloc)
            
            critical_fixes.append({
                "issue": "Hi√°nyz√≥ H1 elem",
                "severity": "critical",
                "impact": "Gyenge tartalom strukt√∫ra AI-k sz√°m√°ra",
                "fix_code": f'<h1>{suggested_h1}</h1>',
                "explanation": "H1 az oldal f≈ë t√©m√°j√°t jel√∂li",
                "estimated_time": "1 perc",
                "implementation": "F≈ëtartalom elej√©n helyezd el"
            })
        
        # T√∂bb H1 elem
        if meta_data.get("h1_count", 0) > 1:
            critical_fixes.append({
                "issue": "T√∫l sok H1 elem",
                "severity": "high",
                "impact": "Zavar√≥ strukt√∫ra AI rendszerek sz√°m√°ra",
                "fix_code": "<!-- Csak egy H1-et tarts meg, a t√∂bbit H2-re cser√©ld -->\n<h2>Alc√≠m</h2>",
                "explanation": "Csak egy H1 legyen oldalank√©nt",
                "estimated_time": "5 perc",
                "implementation": "T√∂bbi H1-et H2, H3 stb. elemre cser√©ld"
            })
        
        return critical_fixes
    
    def _generate_seo_improvements(self, analysis: Dict, url: str) -> List[Dict]:
        """SEO fejleszt√©sek - JAV√çTVA"""
        seo_fixes = []
        
        meta_data = analysis.get("meta_and_headings", {})
        
        # JAV√çT√ÅS: Biztons√°gos title kezel√©s
        title = meta_data.get("title")
        if title:  # Csak ha van title
            title_length = len(title)
            
            if not meta_data.get("title_optimal"):
                if title_length < 30:
                    seo_fixes.append({
                        "issue": "T√∫l r√∂vid title",
                        "current_length": title_length,
                        "optimal_range": "30-60 karakter",
                        "suggestion": f"B≈ëv√≠tsd ki: '{title}' ‚Üí '{title} - {self._suggest_title_extension(url)}'",
                        "fix_code": f'<title>{title} - {self._suggest_title_extension(url)}</title>',
                        "impact": "Jobb SEO teljes√≠tm√©ny √©s AI megjelen√©s"
                    })
                elif title_length > 60:
                    shortened = title[:57] + "..."
                    seo_fixes.append({
                        "issue": "T√∫l hossz√∫ title",
                        "current_length": title_length,
                        "optimal_range": "30-60 karakter",
                        "suggestion": f"R√∂vid√≠tsd le: '{title}' ‚Üí '{shortened}'",
                        "fix_code": f'<title>{shortened}</title>',
                        "impact": "Teljes megjelen√©s a keres≈ëkben"
                    })
        
        # JAV√çT√ÅS: Biztons√°gos description kezel√©s
        description = meta_data.get("description")
        if description:  # Csak ha van description
            desc_length = len(description)
            
            if not meta_data.get("description_optimal"):
                if desc_length < 120:
                    extended_desc = description + " " + self._suggest_description_extension(url)
                    seo_fixes.append({
                        "issue": "T√∫l r√∂vid meta description",
                        "current_length": desc_length,
                        "optimal_range": "120-160 karakter",
                        "suggestion": f"B≈ëv√≠tsd ki r√©szletekkel",
                        "fix_code": f'<meta name="description" content="{extended_desc}">',
                        "impact": "T√∂bb inform√°ci√≥ a keres≈ëkben"
                    })
                elif desc_length > 160:
                    shortened_desc = description[:157] + "..."
                    seo_fixes.append({
                        "issue": "T√∫l hossz√∫ meta description",
                        "current_length": desc_length,
                        "optimal_range": "120-160 karakter",
                        "suggestion": "R√∂vid√≠tsd le a legfontosabb inform√°ci√≥kra",
                        "fix_code": f'<meta name="description" content="{shortened_desc}">',
                        "impact": "Teljes megjelen√©s, nincs lev√°g√°s"
                    })
        
        # Open Graph
        if not meta_data.get("has_og_tags"):
            domain = urlparse(url).netloc
            # JAV√çT√ÅS: Biztons√°gos default √©rt√©kek
            og_title = title if title else domain
            og_description = description if description else f"{domain} weboldal"
            
            seo_fixes.append({
                "issue": "Hi√°nyz√≥ Open Graph meta tagek",
                "impact": "Gyenge social media megjelen√©s",
                "fix_code": f'''<meta property="og:title" content="{og_title}">
    <meta property="og:description" content="{og_description}">
    <meta property="og:url" content="{url}">
    <meta property="og:type" content="website">''',
                "implementation": "head szekci√≥ba illeszd be"
            })
        
        return seo_fixes
    
    def _generate_schema_fixes(self, analysis: Dict, url: str) -> List[Dict]:
        """Schema.org jav√≠t√°sok - JAV√çTVA"""
        schema_fixes = []
        
        schema_data = analysis.get("schema", {})
        
        # JAV√çT√ÅS: Biztons√°gos schema count kezel√©s
        schema_count = 0
        if schema_data and "count" in schema_data:
            count_dict = schema_data.get("count", {})
            if isinstance(count_dict, dict):
                schema_count = sum(count_dict.values())
        
        if schema_count == 0:
            # Alapvet≈ë Organization schema
            domain = urlparse(url).netloc
            
            schema_fixes.append({
                "type": "Organization Schema",
                "priority": "high",
                "benefit": "C√©ginform√°ci√≥k strukt√∫r√°lt megjelen√≠t√©se",
                "code": self.schema_templates["organization"].substitute(
                    company_name=domain.replace('www.', '').replace('.com', '').replace('.hu', '').title(),
                    website_url=url,
                    logo_url=f"{url}/logo.png",
                    company_description="C√©g le√≠r√°sa ide ker√ºl",
                    street_address="C√≠m",
                    city="V√°ros",
                    country="Magyarorsz√°g",
                    phone="+36-XX-XXX-XXXX"
                ),
                "implementation": "JSON-LD script tag-k√©nt a head szekci√≥ban"
            })
        
        # FAQ schema javaslat ha sok k√©rd√©s van a tartalomban
        ai_metrics = analysis.get("ai_metrics", {})
        if ai_metrics and isinstance(ai_metrics, dict):
            qa_format = ai_metrics.get("qa_format", {})
            if isinstance(qa_format, dict) and qa_format.get("question_patterns_count", 0) > 3:
                schema_fixes.append({
                    "type": "FAQ Schema",
                    "priority": "medium",
                    "benefit": "K√©rd√©s-v√°lasz megjelen√©s a keres≈ëkben",
                    "code": self.schema_templates["faq"].substitute(
                        question="Gyakori k√©rd√©s?",
                        answer="R√©szletes v√°lasz a k√©rd√©sre."
                    ),
                    "implementation": "Minden FAQ blokkhoz k√ºl√∂n schema",
                    "note": "Automatikusan gener√°lhat√≥ a megl√©v≈ë Q&A tartalmakb√≥l"
                })
        
        # Article schema blog posztokhoz
        if "blog" in url.lower() or "post" in url.lower() or "cikk" in url.lower():
            # JAV√çT√ÅS: Biztons√°gos title kezel√©s
            meta_data = analysis.get("meta_and_headings", {})
            article_title = meta_data.get("title") if meta_data.get("title") else "Cikk c√≠me"
            
            schema_fixes.append({
                "type": "Article Schema",
                "priority": "medium",
                "benefit": "Cikk r√©szletek megjelen√©se AI rendszerekben",
                "code": self.schema_templates["article"].substitute(
                    headline=article_title,
                    author_name="Szerz≈ë neve",
                    publish_date="2024-01-01",
                    modified_date="2024-01-01",
                    article_description="Cikk r√∂vid le√≠r√°sa",
                    article_url=url
                ),
                "implementation": "Minden cikkoldalon"
            })
        
        return schema_fixes
    
    def _generate_content_fixes(self, analysis: Dict) -> List[Dict]:
        """Tartalom optimaliz√°l√°s - JAV√çTVA"""
        content_fixes = []
        
        # AI specifikus metrik√°k alapj√°n
        ai_metrics = analysis.get("ai_metrics", {})
        
        # JAV√çT√ÅS: Biztons√°gos dictionary el√©r√©s
        if ai_metrics and isinstance(ai_metrics, dict):
            # Step-by-step tartalom hi√°nya
            content_structure = ai_metrics.get("content_structure", {})
            if isinstance(content_structure, dict):
                lists = content_structure.get("lists", {})
                if isinstance(lists, dict) and lists.get("ordered", 0) < 2:
                    content_fixes.append({
                        "issue": "Hi√°nyz√≥ step-by-step tartalom",
                        "benefit": "AI rendszerek k√∂nnyebben feldolgozz√°k",
                        "suggestion": "Adj hozz√° sz√°mozott l√©p√©seket",
                        "example_code": '''
    <ol>
    <li>Els≈ë l√©p√©s: R√©szletes le√≠r√°s</li>
    <li>M√°sodik l√©p√©s: Tov√°bbi inform√°ci√≥k</li>
    <li>Harmadik l√©p√©s: Befejez√©s</li>
    </ol>''',
                        "ai_platforms": ["ChatGPT", "Claude", "Gemini"]
                    })
            
            # FAQ szekci√≥ hi√°nya
            qa_format = ai_metrics.get("qa_format", {})
            if isinstance(qa_format, dict):
                qa_score = qa_format.get("qa_score", 0)
                if qa_score < 30:
                    content_fixes.append({
                        "issue": "Gyenge Q&A strukt√∫ra",
                        "benefit": "Jobb megjelen√©s AI v√°laszokban",
                        "suggestion": "Adj hozz√° FAQ szekci√≥t",
                        "example_code": '''
    <section id="faq">
    <h2>Gyakori k√©rd√©sek</h2>
    <div class="faq-item">
        <h3>K√©rd√©s: Hogyan m≈±k√∂dik?</h3>
        <p>V√°lasz: R√©szletes magyar√°zat...</p>
    </div>
    </section>''',
                        "ai_platforms": ["ChatGPT", "Gemini", "Bing Chat"]
                    })
        
        # Tartalom m√©lys√©g
        content_quality = analysis.get("content_quality", {})
        if content_quality and isinstance(content_quality, dict):
            content_depth = content_quality.get("content_depth", {})
            if isinstance(content_depth, dict) and content_depth.get("depth_score", 0) < 50:
                content_fixes.append({
                    "issue": "Fel√ºletes tartalom",
                    "benefit": "Nagyobb tekint√©ly AI rendszerekben",
                    "suggestion": "B≈ëv√≠tsd t√∂bb p√©ld√°val √©s r√©szlettel",
                    "improvements": [
                        "Adj hozz√° konkr√©t p√©ld√°kat",
                        "Statisztik√°k √©s adatok haszn√°lata",
                        "R√©szletes magyar√°zatok",
                        "Szakmai terminol√≥gia"
                    ]
                })
        
        return content_fixes
    
    def _generate_technical_fixes(self, analysis: Dict) -> List[Dict]:
        """Technikai jav√≠t√°sok"""
        technical_fixes = []
        
        # Mobile-friendly hi√°nyoss√°gok
        mobile = analysis.get("mobile_friendly", {})
        if not mobile.get("has_viewport"):
            technical_fixes.append({
                "issue": "Hi√°nyz√≥ viewport meta tag",
                "severity": "high",
                "impact": "Rossz mobil megjelen√©s",
                "fix_code": '<meta name="viewport" content="width=device-width, initial-scale=1.0">',
                "implementation": "head szekci√≥ tetej√©n"
            })
        
        # Robots.txt probl√©ma
        robots = analysis.get("robots_txt", {})
        if not robots.get("can_fetch"):
            technical_fixes.append({
                "issue": "Robots.txt blokkolja az indexel√©st",
                "severity": "critical",
                "impact": "AI rendszerek nem √©rik el az oldalt",
                "fix_code": """User-agent: *
Allow: /
Sitemap: {}/sitemap.xml""".format(analysis.get("url", "")),
                "implementation": "robots.txt f√°jl m√≥dos√≠t√°sa"
            })
        
        # Sitemap hi√°nya
        sitemap = analysis.get("sitemap", {})
        if not sitemap.get("exists"):
            technical_fixes.append({
                "issue": "Hi√°nyz√≥ sitemap",
                "impact": "Lassabb indexel√©s",
                "solution": "XML sitemap gener√°l√°sa",
                "tools": ["WordPress: Yoast SEO", "Online generators", "Google Search Console"],
                "example_url": f"{analysis.get('url', '')}/sitemap.xml"
            })
        
        return technical_fixes
    
    def _generate_ai_fixes(self, analysis: Dict) -> List[Dict]:
        """AI-specifikus optimaliz√°l√°sok"""
        ai_fixes = []
        
        # Platform specifikus javaslatok
        platforms = analysis.get("platform_analysis", {})
        
        for platform_name, platform_data in platforms.items():
            if platform_name == "summary":
                continue
                
            score = platform_data.get("compatibility_score", 0)
            if score < 70:
                ai_fixes.append({
                    "platform": platform_name,
                    "current_score": score,
                    "target_score": 80,
                    "quick_wins": self._get_platform_quick_wins(platform_name, platform_data),
                    "estimated_improvement": f"+{min(20, 80-score)} pont"
                })
        
        # √Åltal√°nos AI optimaliz√°l√°s
        ai_readiness = analysis.get("ai_readiness_score", 0)
        if ai_readiness < 70:
            ai_fixes.append({
                "type": "general_ai_optimization",
                "current_score": ai_readiness,
                "improvements": [
                    "Struktur√°lt tartalom hozz√°ad√°sa",
                    "FAQ szekci√≥ l√©trehoz√°sa", 
                    "Schema.org markup implement√°l√°sa",
                    "Heading hierarchia jav√≠t√°sa",
                    "Cit√°ci√≥k √©s forr√°sok hozz√°ad√°sa"
                ]
            })
        
        return ai_fixes
    
    def _create_implementation_guide(self) -> Dict:
        """Implement√°l√°si √∫tmutat√≥"""
        return {
            "priority_order": [
                "1. Kritikus hib√°k jav√≠t√°sa (title, description, H1)",
                "2. Technikai probl√©m√°k megold√°sa (robots.txt, sitemap)",
                "3. Schema.org markup hozz√°ad√°sa",
                "4. Tartalom optimaliz√°l√°s",
                "5. AI platform specifikus fejleszt√©sek"
            ],
            "estimated_timeline": {
                "critical_fixes": "1-2 √≥ra",
                "technical_fixes": "2-4 √≥ra", 
                "schema_implementation": "4-6 √≥ra",
                "content_optimization": "1-2 nap",
                "platform_optimization": "2-3 nap"
            },
            "testing_checklist": [
                "Google Search Console valid√°l√°s",
                "Schema.org Testing Tool ellen≈ërz√©s",
                "Mobile-Friendly Test",
                "PageSpeed Insights √∫jratesztel√©s",
                "AI platform tesztel√©s (ChatGPT, Claude)"
            ],
            "monitoring": [
                "Search Console hib√°k figyel√©se",
                "Ranking v√°ltoz√°sok k√∂vet√©se",
                "AI platform megjelen√©sek monitoroz√°sa",
                "Heti/havi AI-readiness score ellen≈ërz√©s"
            ]
        }
    
    def _prioritize_fixes(self, fixes: Dict) -> List[Dict]:
        """Jav√≠t√°sok priorit√°s szerinti rendez√©se"""
        all_fixes = []
        
        # Kritikus jav√≠t√°sok (legmagasabb priorit√°s)
        for fix in fixes.get("critical_fixes", []):
            all_fixes.append({
                **fix,
                "category": "critical",
                "priority_score": 100
            })
        
        # Technikai jav√≠t√°sok
        for fix in fixes.get("technical_fixes", []):
            priority_score = 90 if fix.get("severity") == "critical" else 70
            all_fixes.append({
                **fix,
                "category": "technical",
                "priority_score": priority_score
            })
        
        # SEO fejleszt√©sek
        for fix in fixes.get("seo_improvements", []):
            all_fixes.append({
                **fix,
                "category": "seo",
                "priority_score": 60
            })
        
        # Schema jav√≠t√°sok
        for fix in fixes.get("schema_suggestions", []):
            priority_score = 80 if fix.get("priority") == "high" else 50
            all_fixes.append({
                **fix,
                "category": "schema",
                "priority_score": priority_score
            })
        
        # Rendez√©s priorit√°s szerint
        return sorted(all_fixes, key=lambda x: x.get("priority_score", 0), reverse=True)
    
    # Helper met√≥dusok
    def _suggest_title_from_domain(self, domain: str) -> str:
        """Title javaslat domain alapj√°n"""
        clean_domain = domain.replace('www.', '').replace('.com', '').replace('.hu', '')
        return f"{clean_domain.title()} - Professzion√°lis Szolg√°ltat√°sok"
    
    def _suggest_description_from_domain(self, domain: str) -> str:
        """Description javaslat domain alapj√°n"""
        clean_domain = domain.replace('www.', '').replace('.com', '').replace('.hu', '')
        return f"{clean_domain.title()} professzion√°lis szolg√°ltat√°sai. Min≈ës√©gi megold√°sok, tapasztalt csapat, el√©gedett √ºgyfelek. K√©rj √°raj√°nlatot m√©g ma!"
    
    def _suggest_title_extension(self, url: str) -> str:
        """Title kiterjeszt√©s javaslat"""
        domain = urlparse(url).netloc
        if 'blog' in url:
            return "Blog"
        elif 'szolgaltatas' in url or 'service' in url:
            return "Szolg√°ltat√°sok"
        elif 'kapcsolat' in url or 'contact' in url:
            return "Kapcsolat"
        else:
            return "Kezd≈ëlap"
    
    def _suggest_description_extension(self, url: str) -> str:
        """Description kiterjeszt√©s javaslat"""
        if 'blog' in url:
            return "Olvass friss cikkeket √©s szakmai tan√°csokat."
        elif 'szolgaltatas' in url:
            return "Fedezd fel szolg√°ltat√°sainkat √©s k√©rj szem√©lyre szabott aj√°nlatot."
        else:
            return "Tudj meg t√∂bbet r√≥lunk √©s vedd fel vel√ºnk a kapcsolatot."
    
    def _get_platform_quick_wins(self, platform: str, data: Dict) -> List[str]:
        """Platform specifikus gyors nyeres√©gek"""
        quick_wins = []
        
        if platform == "chatgpt":
            if data.get("structured_lists", {}).get("ordered", 0) == 0:
                quick_wins.append("Adj hozz√° sz√°mozott list√°kat")
            if data.get("step_by_step_content", 0) < 3:
                quick_wins.append("Hozz l√©tre step-by-step √∫tmutat√≥t")
        
        elif platform == "claude":
            if data.get("content_length", 0) < 800:
                quick_wins.append("B≈ëv√≠tsd a tartalmat r√©szletekkel")
            if data.get("citations_sources", 0) < 3:
                quick_wins.append("Adj hozz√° hivatkoz√°sokat")
        
        elif platform == "gemini":
            if data.get("multimedia_content", {}).get("images", 0) < 3:
                quick_wins.append("Adj hozz√° relev√°ns k√©peket")
            if data.get("structured_data", 0) < 20:
                quick_wins.append("Implement√°lj Schema.org markup-ot")
        
        elif platform == "bing_chat":
            if data.get("external_references", 0) < 5:
                quick_wins.append("Hivatkozz k√ºls≈ë forr√°sokra")
        
        return quick_wins or ["√Åltal√°nos optimaliz√°l√°s sz√ºks√©ges"]
    
    def generate_fix_report(self, fixes: Dict, url: str) -> str:
        """√ñsszefoglal√≥ jelent√©s gener√°l√°sa"""
        report = f"""
# Automatikus Jav√≠t√°si Javaslatok
## Elemzett URL: {url}

### üö® Kritikus jav√≠t√°sok ({len(fixes.get('critical_fixes', []))})
"""
        
        for fix in fixes.get('critical_fixes', []):
            report += f"""
**{fix['issue']}**
- S√∫lyoss√°g: {fix['severity']}
- Hat√°s: {fix['impact']}
- Megold√°s: `{fix['fix_code']}`
- Id≈ëig√©ny: {fix['estimated_time']}
"""
        
        report += f"""
### ‚öôÔ∏è Technikai jav√≠t√°sok ({len(fixes.get('technical_fixes', []))})
"""
        
        for fix in fixes.get('technical_fixes', []):
            report += f"""
**{fix['issue']}**
- Hat√°s: {fix['impact']}
- Megold√°s: `{fix.get('fix_code', fix.get('solution', 'L√°sd r√©szletek'))}`
"""
        
        report += f"""
### üìà Prioritiz√°lt cselekv√©si terv
"""
        
        for i, action in enumerate(fixes.get('implementation_guide', {}).get('priority_order', []), 1):
            report += f"{i}. {action}\n"
        
        return report